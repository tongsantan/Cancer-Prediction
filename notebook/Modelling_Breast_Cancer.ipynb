{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Wisconsin Diagnostic breast cancer (Classification Problem) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pacakges\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# to show all the columns of the dataframe in the notebeook\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    RepeatedStratifiedKFold, \n",
    "    cross_validate)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    confusion_matrix,\n",
    "    auc,\n",
    "    roc_curve)\n",
    "\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "df_bc = load_breast_cancer() \n",
    "df_bc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                   0.07871        1.0950         0.9053            8.589   \n",
       "1                   0.05667        0.5435         0.7339            3.398   \n",
       "2                   0.05999        0.7456         0.7869            4.585   \n",
       "3                   0.09744        0.4956         1.1560            3.445   \n",
       "4                   0.05883        0.7572         0.7813            5.438   \n",
       "..                      ...           ...            ...              ...   \n",
       "564                 0.05623        1.1760         1.2560            7.673   \n",
       "565                 0.05533        0.7655         2.4630            5.203   \n",
       "566                 0.05648        0.4564         1.0750            3.425   \n",
       "567                 0.07016        0.7260         1.5950            5.772   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "\n",
       "     area error  smoothness error  compactness error  concavity error  \\\n",
       "0        153.40          0.006399            0.04904          0.05373   \n",
       "1         74.08          0.005225            0.01308          0.01860   \n",
       "2         94.03          0.006150            0.04006          0.03832   \n",
       "3         27.23          0.009110            0.07458          0.05661   \n",
       "4         94.44          0.011490            0.02461          0.05688   \n",
       "..          ...               ...                ...              ...   \n",
       "564      158.70          0.010300            0.02891          0.05198   \n",
       "565       99.04          0.005769            0.02423          0.03950   \n",
       "566       48.55          0.005903            0.03731          0.04730   \n",
       "567       86.22          0.006522            0.06158          0.07117   \n",
       "568       19.15          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave points error  symmetry error  fractal dimension error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "3                 0.01867         0.05963                 0.009208   \n",
       "4                 0.01885         0.01756                 0.005115   \n",
       "..                    ...             ...                      ...   \n",
       "564               0.02454         0.01114                 0.004239   \n",
       "565               0.01678         0.01898                 0.002498   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst radius  worst texture  worst perimeter  worst area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "3          14.910          26.50            98.87       567.7   \n",
       "4          22.540          16.67           152.20      1575.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564        25.450          26.40           166.10      2027.0   \n",
       "565        23.690          38.25           155.00      1731.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  malignant  \n",
       "0                  0.2654          0.4601                  0.11890        0.0  \n",
       "1                  0.1860          0.2750                  0.08902        0.0  \n",
       "2                  0.2430          0.3613                  0.08758        0.0  \n",
       "3                  0.2575          0.6638                  0.17300        0.0  \n",
       "4                  0.1625          0.2364                  0.07678        0.0  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115        0.0  \n",
       "565                0.1628          0.2572                  0.06637        0.0  \n",
       "566                0.1418          0.2218                  0.07820        0.0  \n",
       "567                0.2650          0.4087                  0.12400        0.0  \n",
       "568                0.0000          0.2871                  0.07039        1.0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.c_[df_bc.data, df_bc.target]\n",
    "column_names = np.append(df_bc.feature_names, ['malignant'])\n",
    "df = pd.DataFrame(data, columns=column_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>radius_error</th>\n",
       "      <th>texture_error</th>\n",
       "      <th>perimeter_error</th>\n",
       "      <th>area_error</th>\n",
       "      <th>smoothness_error</th>\n",
       "      <th>compactness_error</th>\n",
       "      <th>concavity_error</th>\n",
       "      <th>concave_points_error</th>\n",
       "      <th>symmetry_error</th>\n",
       "      <th>fractal_dimension_error</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean_fractal_dimension  radius_error  texture_error  perimeter_error  \\\n",
       "0                   0.07871        1.0950         0.9053            8.589   \n",
       "1                   0.05667        0.5435         0.7339            3.398   \n",
       "2                   0.05999        0.7456         0.7869            4.585   \n",
       "3                   0.09744        0.4956         1.1560            3.445   \n",
       "4                   0.05883        0.7572         0.7813            5.438   \n",
       "..                      ...           ...            ...              ...   \n",
       "564                 0.05623        1.1760         1.2560            7.673   \n",
       "565                 0.05533        0.7655         2.4630            5.203   \n",
       "566                 0.05648        0.4564         1.0750            3.425   \n",
       "567                 0.07016        0.7260         1.5950            5.772   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "\n",
       "     area_error  smoothness_error  compactness_error  concavity_error  \\\n",
       "0        153.40          0.006399            0.04904          0.05373   \n",
       "1         74.08          0.005225            0.01308          0.01860   \n",
       "2         94.03          0.006150            0.04006          0.03832   \n",
       "3         27.23          0.009110            0.07458          0.05661   \n",
       "4         94.44          0.011490            0.02461          0.05688   \n",
       "..          ...               ...                ...              ...   \n",
       "564      158.70          0.010300            0.02891          0.05198   \n",
       "565       99.04          0.005769            0.02423          0.03950   \n",
       "566       48.55          0.005903            0.03731          0.04730   \n",
       "567       86.22          0.006522            0.06158          0.07117   \n",
       "568       19.15          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave_points_error  symmetry_error  fractal_dimension_error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "3                 0.01867         0.05963                 0.009208   \n",
       "4                 0.01885         0.01756                 0.005115   \n",
       "..                    ...             ...                      ...   \n",
       "564               0.02454         0.01114                 0.004239   \n",
       "565               0.01678         0.01898                 0.002498   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst_radius  worst_texture  worst_perimeter  worst_area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "3          14.910          26.50            98.87       567.7   \n",
       "4          22.540          16.67           152.20      1575.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564        25.450          26.40           166.10      2027.0   \n",
       "565        23.690          38.25           155.00      1731.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst_concave_points  worst_symmetry  worst_fractal_dimension  malignant  \n",
       "0                  0.2654          0.4601                  0.11890        0.0  \n",
       "1                  0.1860          0.2750                  0.08902        0.0  \n",
       "2                  0.2430          0.3613                  0.08758        0.0  \n",
       "3                  0.2575          0.6638                  0.17300        0.0  \n",
       "4                  0.1625          0.2364                  0.07678        0.0  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115        0.0  \n",
       "565                0.1628          0.2572                  0.06637        0.0  \n",
       "566                0.1418          0.2218                  0.07820        0.0  \n",
       "567                0.2650          0.4087                  0.12400        0.0  \n",
       "568                0.0000          0.2871                  0.07039        1.0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malignant\n",
       "1.0    357\n",
       "0.0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['malignant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malignant\n",
       "0    357\n",
       "1    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['malignant'] = df['malignant'].map(lambda x: 1 if x != 1.0 else 0)\n",
    "df['malignant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"./processed_data/cancer.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_shuff_split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>radius_error</th>\n",
       "      <th>texture_error</th>\n",
       "      <th>perimeter_error</th>\n",
       "      <th>area_error</th>\n",
       "      <th>smoothness_error</th>\n",
       "      <th>compactness_error</th>\n",
       "      <th>concavity_error</th>\n",
       "      <th>concave_points_error</th>\n",
       "      <th>symmetry_error</th>\n",
       "      <th>fractal_dimension_error</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean_fractal_dimension  radius_error  texture_error  perimeter_error  \\\n",
       "0                   0.07871        1.0950         0.9053            8.589   \n",
       "1                   0.05667        0.5435         0.7339            3.398   \n",
       "2                   0.05999        0.7456         0.7869            4.585   \n",
       "3                   0.09744        0.4956         1.1560            3.445   \n",
       "4                   0.05883        0.7572         0.7813            5.438   \n",
       "..                      ...           ...            ...              ...   \n",
       "564                 0.05623        1.1760         1.2560            7.673   \n",
       "565                 0.05533        0.7655         2.4630            5.203   \n",
       "566                 0.05648        0.4564         1.0750            3.425   \n",
       "567                 0.07016        0.7260         1.5950            5.772   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "\n",
       "     area_error  smoothness_error  compactness_error  concavity_error  \\\n",
       "0        153.40          0.006399            0.04904          0.05373   \n",
       "1         74.08          0.005225            0.01308          0.01860   \n",
       "2         94.03          0.006150            0.04006          0.03832   \n",
       "3         27.23          0.009110            0.07458          0.05661   \n",
       "4         94.44          0.011490            0.02461          0.05688   \n",
       "..          ...               ...                ...              ...   \n",
       "564      158.70          0.010300            0.02891          0.05198   \n",
       "565       99.04          0.005769            0.02423          0.03950   \n",
       "566       48.55          0.005903            0.03731          0.04730   \n",
       "567       86.22          0.006522            0.06158          0.07117   \n",
       "568       19.15          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave_points_error  symmetry_error  fractal_dimension_error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "3                 0.01867         0.05963                 0.009208   \n",
       "4                 0.01885         0.01756                 0.005115   \n",
       "..                    ...             ...                      ...   \n",
       "564               0.02454         0.01114                 0.004239   \n",
       "565               0.01678         0.01898                 0.002498   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst_radius  worst_texture  worst_perimeter  worst_area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "3          14.910          26.50            98.87       567.7   \n",
       "4          22.540          16.67           152.20      1575.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564        25.450          26.40           166.10      2027.0   \n",
       "565        23.690          38.25           155.00      1731.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst_concave_points  worst_symmetry  worst_fractal_dimension  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['malignant'],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area',\n",
       "       'mean_smoothness', 'mean_compactness', 'mean_concavity',\n",
       "       'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
       "       'radius_error', 'texture_error', 'perimeter_error', 'area_error',\n",
       "       'smoothness_error', 'compactness_error', 'concavity_error',\n",
       "       'concave_points_error', 'symmetry_error', 'fractal_dimension_error',\n",
       "       'worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area',\n",
       "       'worst_smoothness', 'worst_compactness', 'worst_concavity',\n",
       "       'worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>radius_error</th>\n",
       "      <th>texture_error</th>\n",
       "      <th>perimeter_error</th>\n",
       "      <th>area_error</th>\n",
       "      <th>smoothness_error</th>\n",
       "      <th>compactness_error</th>\n",
       "      <th>concavity_error</th>\n",
       "      <th>concave_points_error</th>\n",
       "      <th>symmetry_error</th>\n",
       "      <th>fractal_dimension_error</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>2.873000</td>\n",
       "      <td>4.885000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>542.200000</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.052790</td>\n",
       "      <td>0.078950</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_radius  mean_texture  mean_perimeter    mean_area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean_symmetry  mean_fractal_dimension  radius_error  texture_error  \\\n",
       "count     569.000000              569.000000    569.000000     569.000000   \n",
       "mean        0.181162                0.062798      0.405172       1.216853   \n",
       "std         0.027414                0.007060      0.277313       0.551648   \n",
       "min         0.106000                0.049960      0.111500       0.360200   \n",
       "25%         0.161900                0.057700      0.232400       0.833900   \n",
       "50%         0.179200                0.061540      0.324200       1.108000   \n",
       "75%         0.195700                0.066120      0.478900       1.474000   \n",
       "max         0.304000                0.097440      2.873000       4.885000   \n",
       "\n",
       "       perimeter_error  area_error  smoothness_error  compactness_error  \\\n",
       "count       569.000000  569.000000        569.000000         569.000000   \n",
       "mean          2.866059   40.337079          0.007041           0.025478   \n",
       "std           2.021855   45.491006          0.003003           0.017908   \n",
       "min           0.757000    6.802000          0.001713           0.002252   \n",
       "25%           1.606000   17.850000          0.005169           0.013080   \n",
       "50%           2.287000   24.530000          0.006380           0.020450   \n",
       "75%           3.357000   45.190000          0.008146           0.032450   \n",
       "max          21.980000  542.200000          0.031130           0.135400   \n",
       "\n",
       "       concavity_error  concave_points_error  symmetry_error  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.031894              0.011796        0.020542   \n",
       "std           0.030186              0.006170        0.008266   \n",
       "min           0.000000              0.000000        0.007882   \n",
       "25%           0.015090              0.007638        0.015160   \n",
       "50%           0.025890              0.010930        0.018730   \n",
       "75%           0.042050              0.014710        0.023480   \n",
       "max           0.396000              0.052790        0.078950   \n",
       "\n",
       "       fractal_dimension_error  worst_radius  worst_texture  worst_perimeter  \\\n",
       "count               569.000000    569.000000     569.000000       569.000000   \n",
       "mean                  0.003795     16.269190      25.677223       107.261213   \n",
       "std                   0.002646      4.833242       6.146258        33.602542   \n",
       "min                   0.000895      7.930000      12.020000        50.410000   \n",
       "25%                   0.002248     13.010000      21.080000        84.110000   \n",
       "50%                   0.003187     14.970000      25.410000        97.660000   \n",
       "75%                   0.004558     18.790000      29.720000       125.400000   \n",
       "max                   0.029840     36.040000      49.540000       251.200000   \n",
       "\n",
       "        worst_area  worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       worst_concave_points  worst_symmetry  worst_fractal_dimension  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['malignant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "564    1\n",
       "565    1\n",
       "566    1\n",
       "567    1\n",
       "568    0\n",
       "Name: malignant, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = next(strat_shuff_split.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>radius_error</th>\n",
       "      <th>texture_error</th>\n",
       "      <th>perimeter_error</th>\n",
       "      <th>area_error</th>\n",
       "      <th>smoothness_error</th>\n",
       "      <th>compactness_error</th>\n",
       "      <th>concavity_error</th>\n",
       "      <th>concave_points_error</th>\n",
       "      <th>symmetry_error</th>\n",
       "      <th>fractal_dimension_error</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>20.18</td>\n",
       "      <td>23.97</td>\n",
       "      <td>143.70</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>0.12860</td>\n",
       "      <td>0.34540</td>\n",
       "      <td>0.37540</td>\n",
       "      <td>0.16040</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.08142</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>1.8850</td>\n",
       "      <td>8.649</td>\n",
       "      <td>116.40</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.068350</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.07895</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>23.37</td>\n",
       "      <td>31.72</td>\n",
       "      <td>170.30</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.61640</td>\n",
       "      <td>0.76810</td>\n",
       "      <td>0.25080</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.09964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>16.03</td>\n",
       "      <td>15.51</td>\n",
       "      <td>105.80</td>\n",
       "      <td>793.2</td>\n",
       "      <td>0.09491</td>\n",
       "      <td>0.13710</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.07041</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.05976</td>\n",
       "      <td>0.3371</td>\n",
       "      <td>0.7476</td>\n",
       "      <td>2.629</td>\n",
       "      <td>33.27</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.01467</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>18.76</td>\n",
       "      <td>21.98</td>\n",
       "      <td>124.30</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.14350</td>\n",
       "      <td>0.44780</td>\n",
       "      <td>0.49560</td>\n",
       "      <td>0.19810</td>\n",
       "      <td>0.3019</td>\n",
       "      <td>0.09124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>13.66</td>\n",
       "      <td>15.15</td>\n",
       "      <td>88.27</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.08268</td>\n",
       "      <td>0.07548</td>\n",
       "      <td>0.04249</td>\n",
       "      <td>0.02471</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.05897</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>1.101</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.008356</td>\n",
       "      <td>0.01818</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>14.54</td>\n",
       "      <td>19.64</td>\n",
       "      <td>97.96</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.31040</td>\n",
       "      <td>0.25690</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>0.09638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>17.42</td>\n",
       "      <td>25.56</td>\n",
       "      <td>114.50</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.10060</td>\n",
       "      <td>0.11460</td>\n",
       "      <td>0.16820</td>\n",
       "      <td>0.06597</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.05866</td>\n",
       "      <td>0.5296</td>\n",
       "      <td>1.6670</td>\n",
       "      <td>3.767</td>\n",
       "      <td>58.53</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.085550</td>\n",
       "      <td>0.143800</td>\n",
       "      <td>0.039270</td>\n",
       "      <td>0.02175</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>18.07</td>\n",
       "      <td>28.07</td>\n",
       "      <td>120.40</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>0.17930</td>\n",
       "      <td>0.28030</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.06818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>14.64</td>\n",
       "      <td>15.24</td>\n",
       "      <td>95.77</td>\n",
       "      <td>651.9</td>\n",
       "      <td>0.11320</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.09966</td>\n",
       "      <td>0.07064</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.06346</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.7372</td>\n",
       "      <td>3.814</td>\n",
       "      <td>42.76</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.044120</td>\n",
       "      <td>0.044360</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>0.02427</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>16.34</td>\n",
       "      <td>18.24</td>\n",
       "      <td>109.40</td>\n",
       "      <td>803.6</td>\n",
       "      <td>0.12770</td>\n",
       "      <td>0.30890</td>\n",
       "      <td>0.26040</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.03</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.02923</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>0.1839</td>\n",
       "      <td>2.3420</td>\n",
       "      <td>1.170</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.02671</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>13.30</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>11.89</td>\n",
       "      <td>21.17</td>\n",
       "      <td>76.39</td>\n",
       "      <td>433.8</td>\n",
       "      <td>0.09773</td>\n",
       "      <td>0.08120</td>\n",
       "      <td>0.02555</td>\n",
       "      <td>0.02179</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>0.06290</td>\n",
       "      <td>0.2747</td>\n",
       "      <td>1.2030</td>\n",
       "      <td>1.930</td>\n",
       "      <td>19.53</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.030530</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.02258</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>13.05</td>\n",
       "      <td>27.21</td>\n",
       "      <td>85.09</td>\n",
       "      <td>522.9</td>\n",
       "      <td>0.14260</td>\n",
       "      <td>0.21870</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.08263</td>\n",
       "      <td>0.3075</td>\n",
       "      <td>0.07351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>13.00</td>\n",
       "      <td>25.13</td>\n",
       "      <td>82.61</td>\n",
       "      <td>520.2</td>\n",
       "      <td>0.08369</td>\n",
       "      <td>0.05073</td>\n",
       "      <td>0.01206</td>\n",
       "      <td>0.01762</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.2621</td>\n",
       "      <td>1.2320</td>\n",
       "      <td>1.657</td>\n",
       "      <td>21.19</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.01215</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>14.34</td>\n",
       "      <td>31.88</td>\n",
       "      <td>91.06</td>\n",
       "      <td>628.5</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.05921</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.06291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>14.20</td>\n",
       "      <td>20.53</td>\n",
       "      <td>92.41</td>\n",
       "      <td>618.4</td>\n",
       "      <td>0.08931</td>\n",
       "      <td>0.11080</td>\n",
       "      <td>0.05063</td>\n",
       "      <td>0.03058</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.06009</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>1.0180</td>\n",
       "      <td>2.749</td>\n",
       "      <td>31.01</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.01610</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>16.45</td>\n",
       "      <td>27.26</td>\n",
       "      <td>112.10</td>\n",
       "      <td>828.5</td>\n",
       "      <td>0.11530</td>\n",
       "      <td>0.34290</td>\n",
       "      <td>0.25120</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>0.07858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>19.79</td>\n",
       "      <td>25.12</td>\n",
       "      <td>130.40</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>0.25450</td>\n",
       "      <td>0.11490</td>\n",
       "      <td>0.2202</td>\n",
       "      <td>0.06113</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>1.1990</td>\n",
       "      <td>2.765</td>\n",
       "      <td>63.33</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.031790</td>\n",
       "      <td>0.047550</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.01578</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>22.63</td>\n",
       "      <td>33.58</td>\n",
       "      <td>148.70</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.38610</td>\n",
       "      <td>0.56730</td>\n",
       "      <td>0.17320</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.08465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "78         20.18         23.97          143.70     1245.0          0.12860   \n",
       "330        16.03         15.51          105.80      793.2          0.09491   \n",
       "378        13.66         15.15           88.27      580.6          0.08268   \n",
       "213        17.42         25.56          114.50      948.0          0.10060   \n",
       "89         14.64         15.24           95.77      651.9          0.11320   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "37         13.03         18.42           82.61      523.8          0.08983   \n",
       "415        11.89         21.17           76.39      433.8          0.09773   \n",
       "458        13.00         25.13           82.61      520.2          0.08369   \n",
       "476        14.20         20.53           92.41      618.4          0.08931   \n",
       "129        19.79         25.12          130.40     1192.0          0.10150   \n",
       "\n",
       "     mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "78            0.34540         0.37540              0.16040         0.2906   \n",
       "330           0.13710         0.12040              0.07041         0.1782   \n",
       "378           0.07548         0.04249              0.02471         0.1792   \n",
       "213           0.11460         0.16820              0.06597         0.1308   \n",
       "89            0.13390         0.09966              0.07064         0.2116   \n",
       "..                ...             ...                  ...            ...   \n",
       "37            0.03766         0.02562              0.02923         0.1467   \n",
       "415           0.08120         0.02555              0.02179         0.2019   \n",
       "458           0.05073         0.01206              0.01762         0.1667   \n",
       "476           0.11080         0.05063              0.03058         0.1506   \n",
       "129           0.15890         0.25450              0.11490         0.2202   \n",
       "\n",
       "     mean_fractal_dimension  radius_error  texture_error  perimeter_error  \\\n",
       "78                  0.08142        0.9317         1.8850            8.649   \n",
       "330                 0.05976        0.3371         0.7476            2.629   \n",
       "378                 0.05897        0.1402         0.5417            1.101   \n",
       "213                 0.05866        0.5296         1.6670            3.767   \n",
       "89                  0.06346        0.5115         0.7372            3.814   \n",
       "..                      ...           ...            ...              ...   \n",
       "37                  0.05863        0.1839         2.3420            1.170   \n",
       "415                 0.06290        0.2747         1.2030            1.930   \n",
       "458                 0.05449        0.2621         1.2320            1.657   \n",
       "476                 0.06009        0.3478         1.0180            2.749   \n",
       "129                 0.06113        0.4953         1.1990            2.765   \n",
       "\n",
       "     area_error  smoothness_error  compactness_error  concavity_error  \\\n",
       "78       116.40          0.010380           0.068350         0.109100   \n",
       "330       33.27          0.005839           0.032450         0.037150   \n",
       "378       11.35          0.005212           0.029840         0.024430   \n",
       "213       58.53          0.031130           0.085550         0.143800   \n",
       "89        42.76          0.005508           0.044120         0.044360   \n",
       "..          ...               ...                ...              ...   \n",
       "37        14.16          0.004352           0.004899         0.013430   \n",
       "415       19.53          0.009895           0.030530         0.016300   \n",
       "458       21.19          0.006054           0.008974         0.005681   \n",
       "476       31.01          0.004107           0.032880         0.028210   \n",
       "129       63.33          0.005033           0.031790         0.047550   \n",
       "\n",
       "     concave_points_error  symmetry_error  fractal_dimension_error  \\\n",
       "78               0.025930         0.07895                 0.005987   \n",
       "330              0.014590         0.01467                 0.003121   \n",
       "378              0.008356         0.01818                 0.004868   \n",
       "213              0.039270         0.02175                 0.012560   \n",
       "89               0.016230         0.02427                 0.004841   \n",
       "..                    ...             ...                      ...   \n",
       "37               0.011640         0.02671                 0.001777   \n",
       "415              0.009276         0.02258                 0.002272   \n",
       "458              0.006336         0.01215                 0.001514   \n",
       "476              0.013500         0.01610                 0.002744   \n",
       "129              0.010430         0.01578                 0.003224   \n",
       "\n",
       "     worst_radius  worst_texture  worst_perimeter  worst_area  \\\n",
       "78          23.37          31.72           170.30      1623.0   \n",
       "330         18.76          21.98           124.30      1070.0   \n",
       "378         14.54          19.64            97.96       657.0   \n",
       "213         18.07          28.07           120.40      1021.0   \n",
       "89          16.34          18.24           109.40       803.6   \n",
       "..            ...            ...              ...         ...   \n",
       "37          13.30          22.81            84.46       545.9   \n",
       "415         13.05          27.21            85.09       522.9   \n",
       "458         14.34          31.88            91.06       628.5   \n",
       "476         16.45          27.26           112.10       828.5   \n",
       "129         22.63          33.58           148.70      1589.0   \n",
       "\n",
       "     worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "78            0.16390            0.61640          0.76810   \n",
       "330           0.14350            0.44780          0.49560   \n",
       "378           0.12750            0.31040          0.25690   \n",
       "213           0.12430            0.17930          0.28030   \n",
       "89            0.12770            0.30890          0.26040   \n",
       "..                ...                ...              ...   \n",
       "37            0.09701            0.04619          0.04833   \n",
       "415           0.14260            0.21870          0.11640   \n",
       "458           0.12180            0.10930          0.04462   \n",
       "476           0.11530            0.34290          0.25120   \n",
       "129           0.12750            0.38610          0.56730   \n",
       "\n",
       "     worst_concave_points  worst_symmetry  worst_fractal_dimension  malignant  \n",
       "78                0.25080          0.5440                  0.09964          1  \n",
       "330               0.19810          0.3019                  0.09124          1  \n",
       "378               0.10540          0.3387                  0.09638          0  \n",
       "213               0.10990          0.1603                  0.06818          1  \n",
       "89                0.13970          0.3151                  0.08473          0  \n",
       "..                    ...             ...                      ...        ...  \n",
       "37                0.05013          0.1987                  0.06169          0  \n",
       "415               0.08263          0.3075                  0.07351          0  \n",
       "458               0.05921          0.2306                  0.06291          0  \n",
       "476               0.13390          0.2534                  0.07858          0  \n",
       "129               0.17320          0.3305                  0.08465          1  \n",
       "\n",
       "[398 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = df.loc[train_idx]  \n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>radius_error</th>\n",
       "      <th>texture_error</th>\n",
       "      <th>perimeter_error</th>\n",
       "      <th>area_error</th>\n",
       "      <th>smoothness_error</th>\n",
       "      <th>compactness_error</th>\n",
       "      <th>concavity_error</th>\n",
       "      <th>concave_points_error</th>\n",
       "      <th>symmetry_error</th>\n",
       "      <th>fractal_dimension_error</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>14.53</td>\n",
       "      <td>19.34</td>\n",
       "      <td>94.25</td>\n",
       "      <td>659.7</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>0.08817</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.05746</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>1.3540</td>\n",
       "      <td>1.994</td>\n",
       "      <td>23.04</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.020480</td>\n",
       "      <td>0.033790</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>16.300</td>\n",
       "      <td>28.39</td>\n",
       "      <td>108.10</td>\n",
       "      <td>830.5</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.26490</td>\n",
       "      <td>0.37790</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.2471</td>\n",
       "      <td>0.07463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>12.06</td>\n",
       "      <td>18.90</td>\n",
       "      <td>76.66</td>\n",
       "      <td>445.3</td>\n",
       "      <td>0.08386</td>\n",
       "      <td>0.05794</td>\n",
       "      <td>0.00751</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.06048</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>1.1520</td>\n",
       "      <td>1.559</td>\n",
       "      <td>18.02</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.01982</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>13.640</td>\n",
       "      <td>27.06</td>\n",
       "      <td>86.54</td>\n",
       "      <td>562.6</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.13520</td>\n",
       "      <td>0.04506</td>\n",
       "      <td>0.05093</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.08083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>1.3870</td>\n",
       "      <td>1.342</td>\n",
       "      <td>13.54</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.010560</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>0.01718</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>12.410</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.13690</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>12.75</td>\n",
       "      <td>16.70</td>\n",
       "      <td>82.51</td>\n",
       "      <td>493.8</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.11170</td>\n",
       "      <td>0.03880</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>0.06623</td>\n",
       "      <td>0.3834</td>\n",
       "      <td>1.0030</td>\n",
       "      <td>2.495</td>\n",
       "      <td>28.62</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.01805</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>14.450</td>\n",
       "      <td>21.74</td>\n",
       "      <td>93.63</td>\n",
       "      <td>624.1</td>\n",
       "      <td>0.14750</td>\n",
       "      <td>0.19790</td>\n",
       "      <td>0.14230</td>\n",
       "      <td>0.08045</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>0.08557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>12.31</td>\n",
       "      <td>16.52</td>\n",
       "      <td>79.19</td>\n",
       "      <td>470.9</td>\n",
       "      <td>0.09172</td>\n",
       "      <td>0.06829</td>\n",
       "      <td>0.03372</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>1.0250</td>\n",
       "      <td>1.740</td>\n",
       "      <td>19.68</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.018190</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.01386</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>14.110</td>\n",
       "      <td>23.21</td>\n",
       "      <td>89.71</td>\n",
       "      <td>611.1</td>\n",
       "      <td>0.11760</td>\n",
       "      <td>0.18430</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.08660</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.07609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>13.48</td>\n",
       "      <td>20.82</td>\n",
       "      <td>88.40</td>\n",
       "      <td>559.2</td>\n",
       "      <td>0.10160</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.054390</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.06419</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>1.545</td>\n",
       "      <td>18.52</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.022390</td>\n",
       "      <td>0.030490</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.01377</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>15.530</td>\n",
       "      <td>26.02</td>\n",
       "      <td>107.30</td>\n",
       "      <td>740.4</td>\n",
       "      <td>0.16100</td>\n",
       "      <td>0.42250</td>\n",
       "      <td>0.50300</td>\n",
       "      <td>0.22580</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.10710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>14.42</td>\n",
       "      <td>19.77</td>\n",
       "      <td>94.48</td>\n",
       "      <td>642.5</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.09388</td>\n",
       "      <td>0.058390</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.06390</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>1.8510</td>\n",
       "      <td>2.376</td>\n",
       "      <td>26.85</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.028950</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.014240</td>\n",
       "      <td>0.01462</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>16.330</td>\n",
       "      <td>30.86</td>\n",
       "      <td>109.50</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.31940</td>\n",
       "      <td>0.15650</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>11.93</td>\n",
       "      <td>21.53</td>\n",
       "      <td>76.53</td>\n",
       "      <td>438.6</td>\n",
       "      <td>0.09768</td>\n",
       "      <td>0.07849</td>\n",
       "      <td>0.03328</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>2.000</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.018350</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.01278</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>13.670</td>\n",
       "      <td>26.15</td>\n",
       "      <td>87.54</td>\n",
       "      <td>583.0</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.23990</td>\n",
       "      <td>0.15030</td>\n",
       "      <td>0.07247</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.08541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>19.53</td>\n",
       "      <td>32.47</td>\n",
       "      <td>128.00</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>0.08420</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>0.11450</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.05313</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>1.3210</td>\n",
       "      <td>4.722</td>\n",
       "      <td>109.90</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.026440</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.01332</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>27.900</td>\n",
       "      <td>45.41</td>\n",
       "      <td>180.20</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>0.14080</td>\n",
       "      <td>0.40970</td>\n",
       "      <td>0.39950</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "448        14.53         19.34           94.25      659.7          0.08388   \n",
       "346        12.06         18.90           76.66      445.3          0.08386   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "411        11.04         16.83           70.92      373.2          0.10770   \n",
       "519        12.75         16.70           82.51      493.8          0.11250   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "74         12.31         16.52           79.19      470.9          0.09172   \n",
       "39         13.48         20.82           88.40      559.2          0.10160   \n",
       "99         14.42         19.77           94.48      642.5          0.09752   \n",
       "115        11.93         21.53           76.53      438.6          0.09768   \n",
       "219        19.53         32.47          128.00     1223.0          0.08420   \n",
       "\n",
       "     mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "448           0.07800         0.08817             0.029250         0.1473   \n",
       "346           0.05794         0.00751             0.008488         0.1555   \n",
       "568           0.04362         0.00000             0.000000         0.1587   \n",
       "411           0.07804         0.03046             0.024800         0.1714   \n",
       "519           0.11170         0.03880             0.029950         0.2120   \n",
       "..                ...             ...                  ...            ...   \n",
       "74            0.06829         0.03372             0.022720         0.1720   \n",
       "39            0.12550         0.10630             0.054390         0.1720   \n",
       "99            0.11410         0.09388             0.058390         0.1879   \n",
       "115           0.07849         0.03328             0.020080         0.1688   \n",
       "219           0.11300         0.11450             0.066370         0.1428   \n",
       "\n",
       "     mean_fractal_dimension  radius_error  texture_error  perimeter_error  \\\n",
       "448                 0.05746        0.2535         1.3540            1.994   \n",
       "346                 0.06048        0.2430         1.1520            1.559   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "411                 0.06340        0.1967         1.3870            1.342   \n",
       "519                 0.06623        0.3834         1.0030            2.495   \n",
       "..                      ...           ...            ...              ...   \n",
       "74                  0.05914        0.2505         1.0250            1.740   \n",
       "39                  0.06419        0.2130         0.5914            1.545   \n",
       "99                  0.06390        0.2895         1.8510            2.376   \n",
       "115                 0.06194        0.3118         0.9227            2.000   \n",
       "219                 0.05313        0.7392         1.3210            4.722   \n",
       "\n",
       "     area_error  smoothness_error  compactness_error  concavity_error  \\\n",
       "448       23.04          0.004147           0.020480         0.033790   \n",
       "346       18.02          0.007180           0.010960         0.005832   \n",
       "568       19.15          0.007189           0.004660         0.000000   \n",
       "411       13.54          0.005158           0.009355         0.010560   \n",
       "519       28.62          0.007509           0.015610         0.019770   \n",
       "..          ...               ...                ...              ...   \n",
       "74        19.68          0.004854           0.018190         0.018260   \n",
       "39        18.52          0.005367           0.022390         0.030490   \n",
       "99        26.85          0.008005           0.028950         0.033210   \n",
       "115       24.79          0.007803           0.025070         0.018350   \n",
       "219      109.90          0.005539           0.026440         0.026640   \n",
       "\n",
       "     concave_points_error  symmetry_error  fractal_dimension_error  \\\n",
       "448              0.008848         0.01394                 0.002327   \n",
       "346              0.005495         0.01982                 0.002754   \n",
       "568              0.000000         0.02676                 0.002783   \n",
       "411              0.007483         0.01718                 0.002198   \n",
       "519              0.009199         0.01805                 0.003629   \n",
       "..                    ...             ...                      ...   \n",
       "74               0.007965         0.01386                 0.002304   \n",
       "39               0.012620         0.01377                 0.003187   \n",
       "99               0.014240         0.01462                 0.004452   \n",
       "115              0.007711         0.01278                 0.003856   \n",
       "219              0.010780         0.01332                 0.002256   \n",
       "\n",
       "     worst_radius  worst_texture  worst_perimeter  worst_area  \\\n",
       "448        16.300          28.39           108.10       830.5   \n",
       "346        13.640          27.06            86.54       562.6   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "411        12.410          26.44            79.93       471.4   \n",
       "519        14.450          21.74            93.63       624.1   \n",
       "..            ...            ...              ...         ...   \n",
       "74         14.110          23.21            89.71       611.1   \n",
       "39         15.530          26.02           107.30       740.4   \n",
       "99         16.330          30.86           109.50       826.4   \n",
       "115        13.670          26.15            87.54       583.0   \n",
       "219        27.900          45.41           180.20      2477.0   \n",
       "\n",
       "     worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "448           0.10890            0.26490          0.37790   \n",
       "346           0.12890            0.13520          0.04506   \n",
       "568           0.08996            0.06444          0.00000   \n",
       "411           0.13690            0.14820          0.10670   \n",
       "519           0.14750            0.19790          0.14230   \n",
       "..                ...                ...              ...   \n",
       "74            0.11760            0.18430          0.17030   \n",
       "39            0.16100            0.42250          0.50300   \n",
       "99            0.14310            0.30260          0.31940   \n",
       "115           0.15000            0.23990          0.15030   \n",
       "219           0.14080            0.40970          0.39950   \n",
       "\n",
       "     worst_concave_points  worst_symmetry  worst_fractal_dimension  malignant  \n",
       "448               0.09594          0.2471                  0.07463          0  \n",
       "346               0.05093          0.2880                  0.08083          0  \n",
       "568               0.00000          0.2871                  0.07039          0  \n",
       "411               0.07431          0.2998                  0.07881          0  \n",
       "519               0.08045          0.3071                  0.08557          0  \n",
       "..                    ...             ...                      ...        ...  \n",
       "74                0.08660          0.2618                  0.07609          0  \n",
       "39                0.22580          0.2807                  0.10710          1  \n",
       "99                0.15650          0.2718                  0.09353          1  \n",
       "115               0.07247          0.2438                  0.08541          0  \n",
       "219               0.16250          0.2713                  0.07568          1  \n",
       "\n",
       "[171 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = df.loc[test_idx]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name=\"malignant\"\n",
    "\n",
    "input_feature_train_df=train_set.drop(columns=[target_column_name],axis=1)\n",
    "target_feature_train_df=train_set[target_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_test_df=test_set.drop(columns=[target_column_name],axis=1)\n",
    "target_feature_test_df=test_set[target_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "numerical_columns = X.select_dtypes(exclude=\"object\").columns\n",
    "categorical_columns = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "num_pipeline= Pipeline(\n",
    "                steps=[ \n",
    "                        (\"scaler\",StandardScaler())\n",
    "                      ]\n",
    "                    )\n",
    "                                    \n",
    "preprocessor=ColumnTransformer(\n",
    "                [\n",
    "                    (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "                ]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_train_arr=preprocessor.fit_transform(input_feature_train_df)\n",
    "input_feature_test_arr=preprocessor.transform(input_feature_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Machine Learning Modelling  <a id=\"part9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split  <a id=\"part9.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "train_arr = np.c_[input_feature_train_arr, np.array(target_feature_train_df)]\n",
    "\n",
    "test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "\n",
    "X_train,y_train,X_test,y_test=(\n",
    "                train_arr[:,:-1],\n",
    "                train_arr[:,-1],\n",
    "                test_arr[:,:-1],\n",
    "                test_arr[:,-1]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.70581999,  1.04974466,  2.12129465, ...,  2.04939907,\n",
       "         3.94428119,  0.86655367],\n",
       "       [ 0.53638811, -0.90994477,  0.5690952 , ...,  1.25584994,\n",
       "         0.16797759,  0.40524244],\n",
       "       [-0.13145612, -0.99333581, -0.14884823, ..., -0.14001353,\n",
       "         0.74198821,  0.68752098],\n",
       "       ...,\n",
       "       [-0.31743806,  1.31844912, -0.38065427, ..., -0.835536  ,\n",
       "        -0.944168  , -1.15058462],\n",
       "       [ 0.02071092,  0.25289695,  0.02070601, ...,  0.28913543,\n",
       "        -0.58853098, -0.2900195 ],\n",
       "       [ 1.59592158,  1.3161327 ,  1.57659141, ...,  0.88090926,\n",
       "         0.61408367,  0.04333279]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_kfolds(cv):\n",
    "    model = list(models.values())[i]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #create an serach and evaluation ranges for depth and features\n",
    "    para=params[list(models.keys())[i]]\n",
    "    \n",
    "    gs = GridSearchCV(model,para, n_jobs = -1, scoring = 'roc_auc')\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = cross_validate(gs, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_error(y_true, y_pred, label):\n",
    "    return pd.Series({'accuracy': accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true, y_pred),\n",
    "                      'recall': recall_score(y_true, y_pred),\n",
    "                      'f1': f1_score(y_true, y_pred)},\n",
    "                      name=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(y_test, y_test_pred):\n",
    "    cm = confusion_matrix(y_test, y_test_pred)         \n",
    "    plt.title('Confusion Matrix (Test Data)')\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_roc_curve(y_test, y_test_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "    auc_ = auc(fpr, tpr)\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='Classifier (area = {:.3f})'.format(auc_))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training with RepeatedStratifiedKFold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-folds=5\n",
      "0.9882022988505748\n",
      "\n",
      "k-folds=6\n",
      "0.9867284488321074\n",
      "\n",
      "k-folds=7\n",
      "0.9872323821303413\n",
      "\n",
      "k-folds=8\n",
      "0.9859208094581211\n",
      "\n",
      "k-folds=9\n",
      "0.9869370201784418\n",
      "\n",
      "k-folds=10\n",
      "0.986552380952381\n",
      "\n",
      "k-NN\n",
      "----\n",
      "Model performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.964824</td>\n",
       "      <td>0.953216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.934426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.964824  0.953216\n",
       "precision  0.985507  0.982759\n",
       "recall     0.918919  0.890625\n",
       "f1         0.951049  0.934426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n",
      "k-folds=5\n",
      "0.9252137931034483\n",
      "\n",
      "k-folds=6\n",
      "0.9259662537101562\n",
      "\n",
      "k-folds=7\n",
      "0.9220003730207811\n",
      "\n",
      "k-folds=8\n",
      "0.9349643640350878\n",
      "\n",
      "k-folds=9\n",
      "0.9391726212089774\n",
      "\n",
      "k-folds=10\n",
      "0.9238952380952382\n",
      "\n",
      "Decision Tree\n",
      "-------------\n",
      "Model performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.953216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.994975  0.953216\n",
       "precision  1.000000  1.000000\n",
       "recall     0.986486  0.875000\n",
       "f1         0.993197  0.933333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n",
      "k-folds=5\n",
      "0.9861609195402299\n",
      "\n",
      "k-folds=6\n",
      "0.9930024841915085\n",
      "\n",
      "k-folds=7\n",
      "0.9939070000294491\n",
      "\n",
      "k-folds=8\n",
      "0.9904292822109035\n",
      "\n",
      "k-folds=9\n",
      "0.9889819353667393\n",
      "\n",
      "k-folds=10\n",
      "0.9920952380952383\n",
      "\n",
      "SVM\n",
      "---\n",
      "Model performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.970760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.989950  0.970760\n",
       "precision  1.000000  0.983607\n",
       "recall     0.972973  0.937500\n",
       "f1         0.986301  0.960000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n",
      "k-folds=5\n",
      "0.9779264367816092\n",
      "\n",
      "k-folds=6\n",
      "0.9786348238482385\n",
      "\n",
      "k-folds=7\n",
      "0.9773453681616947\n",
      "\n",
      "k-folds=8\n",
      "0.9761763700245236\n",
      "\n",
      "k-folds=9\n",
      "0.9806990697513575\n",
      "\n",
      "k-folds=10\n",
      "0.9761714285714286\n",
      "\n",
      "BernoulliNB\n",
      "-----------\n",
      "Model performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.937186</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.950820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.916944</td>\n",
       "      <td>0.928000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.937186  0.947368\n",
       "precision  0.901961  0.950820\n",
       "recall     0.932432  0.906250\n",
       "f1         0.916944  0.928000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n",
      "k-folds=5\n",
      "0.9916413793103448\n",
      "\n",
      "k-folds=6\n",
      "0.994971125306491\n",
      "\n",
      "k-folds=7\n",
      "0.9946780732495019\n",
      "\n",
      "k-folds=8\n",
      "0.9921981848943595\n",
      "\n",
      "k-folds=9\n",
      "0.9943399427672303\n",
      "\n",
      "k-folds=10\n",
      "0.9942857142857143\n",
      "\n",
      "LogisticRegression\n",
      "------------------\n",
      "Model performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.988304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.986111</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.979899  0.988304\n",
       "precision  0.986111  1.000000\n",
       "recall     0.959459  0.968750\n",
       "f1         0.972603  0.984127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n",
      "k-folds=5\n",
      "0.9891540229885057\n",
      "\n",
      "k-folds=6\n",
      "0.9930216802168021\n",
      "\n",
      "k-folds=7\n",
      "0.9901075870463626\n",
      "\n",
      "k-folds=8\n",
      "0.9899838326495001\n",
      "\n",
      "k-folds=9\n",
      "0.9920813232700488\n",
      "\n",
      "k-folds=10\n",
      "0.9917714285714286\n",
      "\n",
      "HistGradientBoostingClassifier\n",
      "------------------------------\n",
      "Model performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train      test\n",
       "accuracy     1.0  0.953216\n",
       "precision    1.0  1.000000\n",
       "recall       1.0  0.875000\n",
       "f1           1.0  0.933333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n",
      "k-folds=5\n",
      "0.9879080459770115\n",
      "\n",
      "k-folds=6\n",
      "0.9926469544457349\n",
      "\n",
      "k-folds=7\n",
      "0.9912457912457912\n",
      "\n",
      "k-folds=8\n",
      "0.9896964458356914\n",
      "\n",
      "k-folds=9\n",
      "0.9917384777985269\n",
      "\n",
      "k-folds=10\n",
      "0.9923428571428572\n",
      "\n",
      "XGBClassifier\n",
      "-------------\n",
      "Model performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train      test\n",
       "accuracy     1.0  0.988304\n",
       "precision    1.0  1.000000\n",
       "recall       1.0  0.968750\n",
       "f1           1.0  0.984127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n",
      "k-folds=5\n",
      "0.9877655172413793\n",
      "\n",
      "k-folds=6\n",
      "0.9905258743063622\n",
      "\n",
      "k-folds=7\n",
      "0.9881722963355617\n",
      "\n",
      "k-folds=8\n",
      "0.9901253153886058\n",
      "\n",
      "k-folds=9\n",
      "0.9913372756510012\n",
      "\n",
      "k-folds=10\n",
      "0.9904380952380952\n",
      "\n",
      "GradientBoostClassifier\n",
      "-----------------------\n",
      "Model performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train      test\n",
       "accuracy     1.0  0.964912\n",
       "precision    1.0  1.000000\n",
       "recall       1.0  0.906250\n",
       "f1           1.0  0.950820"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "            \"k-NN\": KNeighborsClassifier(),\n",
    "            \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "            \"SVM\": svm.SVC(),\n",
    "            \"BernoulliNB\": BernoulliNB(),\n",
    "            \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "            \"HistGradientBoostingClassifier\": HistGradientBoostingClassifier(),\n",
    "            \"XGBClassifier\": XGBClassifier(),\n",
    "            \"GradientBoostClassifier\": GradientBoostingClassifier()\n",
    "    \n",
    "         }\n",
    "\n",
    "\n",
    "params={\n",
    "            \"k-NN\": {\"n_neighbors\": [10, 20, 30 , 40]},\n",
    "            \n",
    "            \"Decision Tree\":{\n",
    "                'max_depth': [1, 3, 5, 7],\n",
    "                'max_features': [1, 10, 20 , 30]\n",
    "                            },\n",
    "            \n",
    "            \"SVM\":{  \n",
    "                'kernel': ('linear', 'poly', 'rbf'),\n",
    "                'C': [0.01, 0.1, 1, 10]},\n",
    "    \n",
    "            \"BernoulliNB\":{},\n",
    "    \n",
    "            \"LogisticRegression\":{\n",
    "                'solver': ['lbfgs', 'liblinear', 'newton-cholesky'],\n",
    "                'C': [0.01, 0.1, 1, 10],\n",
    "                'max_iter': [100, 1000, 10000]\n",
    "                                 },\n",
    "            \n",
    "            \"HistGradientBoostingClassifier\":{\n",
    "            'learning_rate':[.1,.01,.05,.001],\n",
    "            'max_depth': [6,8,10]\n",
    "                },\n",
    "     \n",
    "            \"XGBClassifier\":{\n",
    "            'learning_rate':[.1,.01,.001],\n",
    "            'n_estimators': [8,16,32,64,128]\n",
    "                            },\n",
    "     \n",
    "            \"GradientBoostClassifier\":{\n",
    "            'learning_rate':[.1,.01,.05,.001],\n",
    "            'subsample':[0.6,0.7,0.8,0.9],\n",
    "            'n_estimators': [8,16,32,64,128]\n",
    "                                }\n",
    "        }\n",
    "\n",
    "# define folds to test\n",
    "folds = range(5,11)\n",
    "\n",
    "# record each set of results\n",
    "k_fold_list = []\n",
    "model_list = []\n",
    "params_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    # evaluate each k value\n",
    "    for k in folds:\n",
    "        # define the test condition\n",
    "        cv = RepeatedStratifiedKFold(n_splits=k, n_repeats=1, random_state=0)\n",
    "        # evaluate k value\n",
    "        k_mean = evaluate_model_kfolds(cv)\n",
    "        # report performance\n",
    "        print('k-folds=%d' % (k))\n",
    "        print(k_mean)\n",
    "        print()\n",
    "        # store each mean roc_auc into the list\n",
    "        k_fold_list.append(k_mean)\n",
    "        \n",
    "    model = list(models.values())[i]\n",
    "    para=params[list(models.keys())[i]]\n",
    "    gs = GridSearchCV(model,para, n_jobs = -1, scoring = 'roc_auc')\n",
    "    gs.fit(X_train, y_train)\n",
    "    cv = RepeatedStratifiedKFold(n_splits= max(range(len(k_fold_list)), key=k_fold_list.__getitem__) + 2, n_repeats=1, random_state=0)\n",
    "    scores = cross_validate(gs, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
    "    params_list.append(gs.best_params_)\n",
    "    model.set_params(**gs.best_params_)\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "        \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    print(len(list(models.keys())[i]) * '-')\n",
    "\n",
    "    print('Model performance')\n",
    "    train_test_full_error = pd.concat([measure_error(y_train, y_train_pred, 'train'),\n",
    "                                       measure_error(y_test, y_test_pred, 'test')],\n",
    "                                       axis=1)\n",
    "    display(train_test_full_error)\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    accuracy_list.append(train_test_full_error['test'].values[0])\n",
    "    precision_list.append(train_test_full_error['test'].values[1])\n",
    "    recall_list.append(train_test_full_error['test'].values[2])\n",
    "    f1_list.append(train_test_full_error['test'].values[3])\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Recall_Score</th>\n",
       "      <th>Precision_Score</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 100, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.970760</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostClassifier</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 128, 'subsample': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.953216</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953216</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953216</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model Name  F1_Score  Recall_Score  Precision_Score  \\\n",
       "1              LogisticRegression  0.984127      0.968750         1.000000   \n",
       "2                   XGBClassifier  0.984127      0.968750         1.000000   \n",
       "3                             SVM  0.960000      0.937500         0.983607   \n",
       "4         GradientBoostClassifier  0.950820      0.906250         1.000000   \n",
       "5                            k-NN  0.934426      0.890625         0.982759   \n",
       "6                   Decision Tree  0.933333      0.875000         1.000000   \n",
       "7  HistGradientBoostingClassifier  0.933333      0.875000         1.000000   \n",
       "8                     BernoulliNB  0.928000      0.906250         0.950820   \n",
       "\n",
       "   Accuracy_Score  \\\n",
       "1        0.988304   \n",
       "2        0.988304   \n",
       "3        0.970760   \n",
       "4        0.964912   \n",
       "5        0.953216   \n",
       "6        0.953216   \n",
       "7        0.953216   \n",
       "8        0.947368   \n",
       "\n",
       "                                                     Best_Params  \n",
       "1             {'C': 0.1, 'max_iter': 100, 'solver': 'liblinear'}  \n",
       "2                    {'learning_rate': 0.1, 'n_estimators': 128}  \n",
       "3                                     {'C': 10, 'kernel': 'rbf'}  \n",
       "4  {'learning_rate': 0.1, 'n_estimators': 128, 'subsample': 0.6}  \n",
       "5                                            {'n_neighbors': 10}  \n",
       "6                           {'max_depth': 7, 'max_features': 10}  \n",
       "7                         {'learning_rate': 0.1, 'max_depth': 8}  \n",
       "8                                                             {}  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(list(zip(model_list, f1_list,  recall_list, precision_list, accuracy_list, params_list)), columns=['Model Name', 'F1_Score', 'Recall_Score', 'Precision_Score', 'Accuracy_Score', 'Best_Params']).sort_values(by=[\"F1_Score\"],ascending=False).reset_index(drop=True)\n",
    "df_results.index += 1\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression  <a id=\"part9.6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LogR_model = LogisticRegression(C= 0.1, max_iter= 100, solver='liblinear')\n",
    "LogR_model = LogR_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = LogR_model.predict(X_test)\n",
    "\n",
    "display_confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LogR_model = LogisticRegression(C= 0.1, max_iter= 100, solver='liblinear')\n",
    "LogR_model = LogR_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = LogR_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "display_roc_curve(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results\n",
    "After optimization of all models, the best performing Classifiers that give the lowest False Positives and False Negatives are Logistic Regression and XGBClassifier. They have the highest F1 score of 0.984127 amongst others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
