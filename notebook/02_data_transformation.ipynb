{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Vincent\\\\Desktop\\\\Cancer-Prediction-Trials\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Vincent\\\\Desktop\\\\Cancer-Prediction-Trials'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    train_array_path: Path\n",
    "    test_array_path: Path\n",
    "    preprocessor_obj_file_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import *\n",
    "from src.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update the configuration manager in src config\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "\n",
    "        create_directories([self.config.output_root])\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            train_array_path=config.train_array_path,\n",
    "            test_array_path=config.test_array_path,\n",
    "            preprocessor_obj_file_path=config.preprocessor_obj_file_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Update the components\n",
    "\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.exception import CustomException\n",
    "from src import logger\n",
    "from src.utils.common import save_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Update the components\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config=config\n",
    "\n",
    "    def get_data_transformer_object(self):\n",
    "        '''\n",
    "        This function is responsible for data transformation\n",
    "        \n",
    "        '''\n",
    "        try:\n",
    "            numerical_columns = ['mean_radius', 'mean_texture', 'mean_smoothness', 'mean_compactness',\n",
    "       'mean_concavity', 'mean_concave_points', 'mean_symmetry']\n",
    "            \n",
    "            num_pipeline= Pipeline(\n",
    "                    steps=[\n",
    "                            (\"scaler\",StandardScaler())\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            logger.info(f\"Numerical columns: {numerical_columns}\")\n",
    "\n",
    "            preprocessor=ColumnTransformer(\n",
    "                    [\n",
    "                        (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            return preprocessor\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "        \n",
    "    def initiate_data_transformation(self):\n",
    "\n",
    "        try:\n",
    "            train_df=pd.read_csv(self.config.train_data_path)\n",
    "            test_df=pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "            logger.info(\"Read train and test data completed\")\n",
    "\n",
    "            logger.info(\"Obtaining preprocessing object\")\n",
    "\n",
    "            preprocessing_obj=self.get_data_transformer_object()\n",
    "\n",
    "            target_column_name=\"malignant\"\n",
    "\n",
    "            input_feature_train_df=train_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_train_df=train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df=test_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_test_df=test_df[target_column_name]\n",
    "\n",
    "            logger.info(\n",
    "                f\"Applying preprocessing object on training dataframe and testing dataframe.\"\n",
    "            )\n",
    "\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "            ]\n",
    "            \n",
    "            test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "\n",
    "            np.save(self.config.train_array_path, train_arr)\n",
    "            np.save(self.config.test_array_path, test_arr)\n",
    "\n",
    "\n",
    "            logger.info(f\"Saved preprocessing object.\")\n",
    "\n",
    "            save_object(\n",
    "\n",
    "                file_path=self.config.preprocessor_obj_file_path,\n",
    "                obj=preprocessing_obj\n",
    "\n",
    "            )\n",
    "\n",
    "            return (\n",
    "                self.config.train_array_path,\n",
    "                self.config.test_array_path,\n",
    "                self.config.preprocessor_obj_file_path,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-12 12:50:29,633: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-07-12 12:50:29,634: INFO: common: created directory at: output]\n",
      "[2024-07-12 12:50:29,634: INFO: common: created directory at: output/data_transformation]\n",
      "[2024-07-12 12:50:29,634: INFO: 4186927068: Numerical columns: ['mean_radius', 'mean_texture', 'mean_smoothness', 'mean_compactness', 'mean_concavity', 'mean_concave_points', 'mean_symmetry']]\n",
      "[2024-07-12 12:50:29,644: INFO: 4186927068: Read train and test data completed]\n",
      "[2024-07-12 12:50:29,645: INFO: 4186927068: Obtaining preprocessing object]\n",
      "[2024-07-12 12:50:29,646: INFO: 4186927068: Numerical columns: ['mean_radius', 'mean_texture', 'mean_smoothness', 'mean_compactness', 'mean_concavity', 'mean_concave_points', 'mean_symmetry']]\n",
      "[2024-07-12 12:50:29,648: INFO: 4186927068: Applying preprocessing object on training dataframe and testing dataframe.]\n",
      "[2024-07-12 12:50:29,655: INFO: 4186927068: Saved preprocessing object.]\n"
     ]
    }
   ],
   "source": [
    "## 6. Update the pipeline\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.get_data_transformer_object()\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "  raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlparamenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
